#!/usr/bin/env python3
"""
Style-Aware Multitask Adapters with Catastrophic Forgetting Resilience
–ù–∞—É—á–Ω–∞—è –Ω–æ–≤–∏–∑–Ω–∞: –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ 4 —Å—Ç–∏–ª–µ–π —Å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ—Ä–µ–Ω—Ü–∏–µ–π
"""

import torch
import json
from pathlib import Path
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import LoraConfig, get_peft_model, PeftModel
import pandas as pd
import numpy as np

class MultiStyleExpert:
    """–ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è 4 —ç–∫—Å–ø–µ—Ä—Ç–∞–º–∏-—Å—Ç–∏–ª—è–º–∏"""
    
    def __init__(self, base_model="sberbank-ai/rugpt3small_based_on_gpt2"):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"üîß –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å –û–î–ò–ù –†–ê–ó
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ SberAI...")
        self.tokenizer = AutoTokenizer.from_pretrained(base_model)
        self.tokenizer.pad_token = self.tokenizer.eos_token
        
        self.base_model = AutoModelForCausalLM.from_pretrained(
            base_model,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
            device_map="auto" if self.device == "cuda" else None
        )
        
        # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
        for param in self.base_model.parameters():
            param.requires_grad = False
        
        self.styles = ["friendly", "formal", "empathetic", "humorous"]
        self.experts = {}
        
    def create_experts(self):
        """–°–æ–∑–¥–∞–µ–º 4 –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–∞ (LoRA –∞–¥–∞–ø—Ç–µ—Ä–∞)"""
        print("üé≠ –°–æ–∑–¥–∞–Ω–∏–µ 4 —Å—Ç–∏–ª–µ–≤—ã—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤...")
        
        for style in self.styles:
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è LoRA –î–õ–Ø –ö–ê–ñ–î–û–ì–û –°–¢–ò–õ–Ø
            lora_config = LoraConfig(
                r=4,  # –ú–µ–Ω—å—à–µ rank –¥–ª—è CPU
                lora_alpha=8,
                target_modules=["attn.c_attn", "attn.c_proj"],  # –¢–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥—É–ª–∏
                lora_dropout=0.1,  # –ë–æ–ª—å—à–µ –¥—Ä–æ–ø–∞—É—Ç–∞ –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
                bias="none",
                task_type="CAUSAL_LM",
            )
            
            # –°–æ–∑–¥–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä –ù–ê –ë–ê–ó–û–í–û–ô –ú–û–î–ï–õ–ò
            expert_model = get_peft_model(self.base_model, lora_config)
            self.experts[style] = expert_model
            print(f"   ‚úÖ –≠–∫—Å–ø–µ—Ä—Ç '{style}' —Å–æ–∑–¥–∞–Ω")
            
    def train_expert(self, style_name, data_path="/content/data/my_style_data.json"):
        """–û–±—É—á–∞–µ–º –æ–¥–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞ –Ω–∞ –µ–≥–æ —Å—Ç–∏–ª–µ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        print(f"\n –û–±—É—á–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–∞: {style_name}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        with open(data_path, 'r', encoding='utf-8') as f:
            all_data = json.load(f)
        
        style_data = all_data.get(style_name, [])
        
        if not style_data:
            print(f"   ‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∏–ª—è {style_name}")
            return
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        texts = []
        for item in style_data:
            prompt = f"–°—Ç–∏–ª—å: {style_name}\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: {item['context']}\n–û—Ç–≤–µ—Ç: {item['response']}"
            texts.append(prompt)
        
        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
        inputs = self.tokenizer(
            texts,
            truncation=True,
            max_length=256,
            padding="max_length",
            return_tensors="pt"
        )
        
        # –ü—Ä–æ—Å—Ç–æ–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è (–¥–ª—è –¥–µ–º–æ)
        expert = self.experts[style_name]
        expert.train()
        
        optimizer = torch.optim.AdamW(expert.parameters(), lr=1e-4)
        
        print(f"   üìä –ü—Ä–∏–º–µ—Ä–æ–≤: {len(texts)}")
        
        for epoch in range(3):  # 3 —ç–ø–æ—Ö–∏
            total_loss = 0
            
            inputs_device = {k: v.to(self.device) for k, v in inputs.items()}
            outputs = expert(**inputs_device, labels=inputs_device['input_ids'])
            
            loss = outputs.loss
            total_loss += loss.item()
            
            # Backward pass
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
            
            print(f"   –≠–ø–æ—Ö–∞ {epoch+1}, Loss: {loss.item():.4f}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¢–û–õ–¨–ö–û –∞–¥–∞–ø—Ç–µ—Ä
        expert.save_pretrained(f"adapters/{style_name}")
        print(f"   üíæ –ê–¥–∞–ø—Ç–µ—Ä '{style_name}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
        
    def run_training(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è"""
        print("="*50)
        print("üéì –ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø MULTI-STYLE EXPERTS")
        print("="*50)
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫—Å–ø–µ—Ä—Ç–æ–≤
        self.create_experts()
        
        # –û–±—É—á–∞–µ–º –∫–∞–∂–¥–æ–≥–æ —ç–∫—Å–ø–µ—Ä—Ç–∞
        for style in self.styles:
            self.train_expert(style)
        
        print("\n" + "="*50)
        print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        print("="*50)
        
    def test_experts(self):
        """–¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä—Ç–æ–≤"""
        print("\nüß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –≠–ö–°–ü–ï–†–¢–û–í")
        print("-"*30)
        
        test_contexts = [
            "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
            "–î–æ–±—Ä—ã–π –¥–µ–Ω—å, –º–Ω–µ –Ω—É–∂–Ω–∞ –ø–æ–º–æ—â—å",
            "–Ø —Ç–∞–∫ —É—Å—Ç–∞–ª –æ—Ç —Ä–∞–±–æ—Ç—ã...",
            "–°–∫—É—á–Ω–æ —Å–∏–¥–µ—Ç—å –¥–æ–º–∞"
        ]
        
        for context in test_contexts:
            print(f"\nüìù –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}")
            
            for style in self.styles:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä
                expert = PeftModel.from_pretrained(
                    self.base_model, 
                    f"adapters/{style}"
                )
                expert.eval()
                
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
                prompt = f"–°—Ç–∏–ª—å: {style}\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}\n–û—Ç–≤–µ—Ç:"
                inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
                
                with torch.no_grad():
                    outputs = expert.generate(
                        **inputs,
                        max_length=100,
                        temperature=0.7,
                        do_sample=True,
                        pad_token_id=self.tokenizer.eos_token_id
                    )
                
                response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
                response = response.split("–û—Ç–≤–µ—Ç:")[-1].strip()
                
                print(f"   {style.upper()}: {response[:50]}...")

# –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    expert_system = MultiStyleExpert()
    expert_system.run_training()
    expert_system.test_experts()